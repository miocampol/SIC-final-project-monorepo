"""
Script simple para cargar textos en Chroma usando embeddings de Ollama
"""
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from procesar_json import procesar_malla_curricular

# 1. Procesar el JSON y obtener textos estructurados
print("ğŸ“– Procesando JSON...")
textos = procesar_malla_curricular("data/documents/malla_curricular_administracion_sistemas_informaticos (1).json")
print(f"âœ… {len(textos)} materias procesadas\n")

# 2. Crear embeddings usando mxbai-embed-large
print("ğŸ”— Creando embeddings con mxbai-embed-large...")
embeddings = OllamaEmbeddings(
    model="mxbai-embed-large",
    base_url="http://localhost:11434"
)

# 3. Crear o cargar Chroma vector store
print("ğŸ’¾ Creando vector store en Chroma...")
vectorstore = Chroma.from_texts(
    texts=textos,
    embedding=embeddings,
    persist_directory="data/vectorstore"
)

print(f"âœ… {len(textos)} documentos cargados en Chroma")
print(f"ğŸ“ Vector store guardado en: data/vectorstore")

# 4. Probar una bÃºsqueda simple
print("\nğŸ” Probando bÃºsqueda...")
resultados = vectorstore.similarity_search("CÃ¡lculo", k=3)

print(f"\nEncontrados {len(resultados)} resultados para 'CÃ¡lculo':")
for i, doc in enumerate(resultados, 1):
    print(f"\n{i}. {doc.page_content[:200]}...")

